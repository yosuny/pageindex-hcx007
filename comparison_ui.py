"""
RAG ë¹„êµ í…ŒìŠ¤íŠ¸ UI v3

Vector RAGì™€ PageIndex RAGì˜ ë‹µë³€ì„ ë‚˜ë€íˆ ë¹„êµí•  ìˆ˜ ìˆëŠ” Gradio ê¸°ë°˜ UIì…ë‹ˆë‹¤.
- ì¢Œì¸¡ ì‚¬ì´ë“œë°”: ë¬¸ì„œ ì„ íƒ
- ë©”ì¸ ì˜ì—­: ì§ˆë¬¸ â†’ ë‹µë³€ â†’ ë¹„êµ ìš”ì•½
"""
import os
import sys
import time
import json
import hashlib
from datetime import datetime
import gradio as gr
from pathlib import Path

# Add project root to path
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from comparison.modules.vector_rag import VectorRAG
from comparison.modules.pageindex_rag import PageIndexRAG
from comparison.modules.pageindex_router import PageIndexRouter

# Initialize RAG systems
print("Initializing RAG systems...")
vector_rag = VectorRAG(chunking_strategy="semantic")
pageindex_rag = PageIndexRAG(thinking_effort="medium")
pageindex_router = PageIndexRouter(thinking_effort="medium")
print("RAG systems initialized!")

# Logging & Caching Setup
LOG_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), "comparison", "data", "logs")
os.makedirs(LOG_DIR, exist_ok=True)
HISTORY_FILE = os.path.join(LOG_DIR, "query_history.json")

def load_history():
    if os.path.exists(HISTORY_FILE):
        try:
            with open(HISTORY_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            return {}
    return {}

def save_history(history):
    with open(HISTORY_FILE, 'w', encoding='utf-8') as f:
        json.dump(history, f, indent=2, ensure_ascii=False)

def get_query_hash(question, docs):
    """Generate MD5 hash based on question and selected documents."""
    content = f"{question}|{'|'.join(sorted(docs))}"
    return hashlib.md5(content.encode()).hexdigest()

def get_recent_queries():
    """Get list of unique recent queries from history."""
    history = load_history()
    # Sort by timestamp desc
    sorted_items = sorted(history.values(), key=lambda x: x.get("timestamp", ""), reverse=True)
    # Extract unique queries
    queries = []
    seen = set()
    for item in sorted_items:
        q = item.get("query", "")
        if q and q not in seen:
            queries.append(q)
            seen.add(q)
    return queries[:15]  # Top 15 recent queries


def load_cached_result(query):
    """Load cached result for the selected query from history."""
    if not query:
        return "", "", "", gr.Dropdown(choices=get_recent_queries())
        
    history = load_history()
    # Find latest entry with this query
    matches = [h for h in history.values() if h.get("query") == query]
    
    if matches:
        # Sort by timestamp desc to get the latest
        matches.sort(key=lambda x: x.get("timestamp", ""), reverse=True)
        cached = matches[0]
        
        # Format cached responses
        v_res = cached["vector_result"]
        p_res = cached["pageindex_result"]
        
        vector_output = f"**â±ï¸ {v_res.get('time', 0):.2f}ì´ˆ (History)**\n\n{v_res.get('answer', '')}"
        
        pi_docs = p_res.get("docs_searched", 0)
        pageindex_output = f"**â±ï¸ {p_res.get('time', 0):.2f}ì´ˆ (History)** ({pi_docs}ê°œ ë¬¸ì„œ ê²€ìƒ‰)\n\n{p_res.get('answer', '')}"
        
        comparison = f"""---
### ğŸ“Š ë¹„êµ ìš”ì•½
| í•­ëª© | Vector RAG | PageIndex RAG |
|:---|:---:|:---:|
| **ì‘ë‹µ ì‹œê°„** | {v_res.get('time', 0):.2f}ì´ˆ (History) | {p_res.get('time', 0):.2f}ì´ˆ (History) |
| **ë‹µë³€ ê¸¸ì´** | {len(v_res.get('answer', ''))} ì | {len(p_res.get('answer', ''))} ì |
"""
        return vector_output, pageindex_output, comparison, gr.Dropdown(choices=get_recent_queries())
    else:
        # No history found for this query
        msg = "âš ï¸ ì €ì¥ëœ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. 'ë¹„êµ ë¶„ì„ ì‹¤í–‰' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”."
        return msg, msg, "", gr.Dropdown(choices=get_recent_queries())


# Get available PDFs
PDF_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), "comparison", "data", "documents")
pdf_files = []
if os.path.exists(PDF_DIR):
    pdf_files = sorted([f for f in os.listdir(PDF_DIR) if f.endswith('.pdf')])

# Detect existing PageIndex caches
pageindex_cached = set()
tree_cache_dir = os.path.join(
    os.path.dirname(os.path.abspath(__file__)), 
    "comparison", "data", "cache", "pageindex_trees"
)
if os.path.exists(tree_cache_dir):
    for cache_file in os.listdir(tree_cache_dir):
        if cache_file.endswith("_tree.json"):
            for pdf in pdf_files:
                pdf_stem = Path(pdf).stem[:30]
                if cache_file.startswith(pdf_stem):
                    pageindex_cached.add(pdf)
                    break

print(f"ì¸ë±ì‹± ìƒíƒœ - Vector: {len(pdf_files)}ê°œ ê°€ëŠ¥, PageIndex ìºì‹œ: {len(pageindex_cached)}ê°œ")


def compare_answers(selected_docs: list, search_all: bool, question: str, progress=gr.Progress()) -> tuple:
    """Compare answers from both RAG systems with caching."""
    if not question:
        return "", "", ""
    
    # Determine which documents to search
    if search_all:
        docs_to_search = pdf_files
    elif selected_docs:
        docs_to_search = selected_docs
    else:
        return "âš ï¸ ë¬¸ì„œë¥¼ ì„ íƒí•˜ê±°ë‚˜ 'ì „ì²´ ë¬¸ì„œ ê²€ìƒ‰'ì„ ì²´í¬í•´ì£¼ì„¸ìš”.", "", ""
    
    # Check Cache
    history = load_history()
    query_hash = get_query_hash(question, docs_to_search)
    
    if query_hash in history:
        cached = history[query_hash]
        print(f"âœ… Cache Hit: {question[:30]}...")
        
        # Format cached responses
        v_res = cached["vector_result"]
        p_res = cached["pageindex_result"]
        
        vector_output = f"**â±ï¸ {v_res.get('time', 0):.2f}ì´ˆ (Cached)**\n\n{v_res.get('answer', '')}"
        
        pi_docs = p_res.get("docs_searched", 0)
        pageindex_output = f"**â±ï¸ {p_res.get('time', 0):.2f}ì´ˆ (Cached)** ({pi_docs}ê°œ ë¬¸ì„œ ê²€ìƒ‰)\n\n{p_res.get('answer', '')}"
        
        comparison = f"""---
### ğŸ“Š ë¹„êµ ìš”ì•½
| í•­ëª© | Vector RAG | PageIndex RAG |
|:---|:---:|:---:|
| **ì‘ë‹µ ì‹œê°„** | {v_res.get('time', 0):.2f}ì´ˆ (Cached) | {p_res.get('time', 0):.2f}ì´ˆ (Cached) |
| **ë‹µë³€ ê¸¸ì´** | {len(v_res.get('answer', ''))} ì | {len(p_res.get('answer', ''))} ì |
"""
        return vector_output, pageindex_output, comparison, gr.Dropdown(choices=get_recent_queries())
    
    
    results = {}
    
    # Vector RAG
    progress(0.2, desc="Vector RAG ë‹µë³€ ìƒì„± ì¤‘...")
    try:
        start = time.time()
        vector_answer = vector_rag.answer(question, top_k=5, thinking_effort="medium")
        vector_time = time.time() - start
        results["vector"] = {"answer": vector_answer, "time": vector_time}
    except Exception as e:
        results["vector"] = {"answer": f"âŒ ì˜¤ë¥˜: {str(e)}", "time": 0}
    
    # PageIndex RAG
    progress(0.4, desc="PageIndex: ë¬¸ì„œ ì„ ë³„ ì¤‘ (Global Routing)...")
    try:
        start = time.time()
        
        # 1. ë¬¸ì„œ ì„ ë³„ (Global Routing)
        available_docs = [d for d in docs_to_search if d in pageindex_cached]
        selected_docs = []
        routing_log = ""
        
        if available_docs:
            try:
                # ë¼ìš°í„°ë¡œ ê´€ë ¨ ë¬¸ì„œ 2ê°œ ì„ ë³„
                selected_docs = pageindex_router.route(question, available_docs, top_k=2)
                routing_log = f"> **ğŸ” ì„ ë³„ëœ ë¬¸ì„œ**: " + ", ".join([f"`{os.path.basename(d)[:20]}...`" for d in selected_docs]) + "\n\n"
            except Exception as re:
                print(f"Router error: {re}")
                selected_docs = available_docs # Fallback
        
        all_pageindex_results = []
        # ì„ ë³„ëœ ë¬¸ì„œë§Œ ê²€ìƒ‰
        progress(0.6, desc=f"PageIndex: {len(selected_docs)}ê°œ ë¬¸ì„œ ì •ë°€ ê²€ìƒ‰ ì¤‘...")
        for doc_name in selected_docs:
            if doc_name in pageindex_cached:
                pdf_path = os.path.join(PDF_DIR, doc_name)
                try:
                    pageindex_rag.build_tree(pdf_path)
                    search_results = pageindex_rag.search(pdf_path, question, top_k=2)
                    for r in search_results:
                        r["source_doc"] = doc_name  # ì „ì²´ ë¬¸ì„œëª… ì‚¬ìš©
                    all_pageindex_results.extend(search_results)
                except:
                    pass
        
        all_pageindex_results = all_pageindex_results[:5]
        
        if all_pageindex_results:
            context_parts = []
            for i, doc in enumerate(all_pageindex_results):
                source = doc.get("source_doc", "Unknown")
                title = doc.get("title", "")
                page = doc.get("page", "?")
                text = doc.get("text", "")[:1500]
                # ë¬¸ì„œëª…ì„ ëŒ€ê´„í˜¸ë¡œ ê°ì‹¸ì„œ ëª…í™•íˆ êµ¬ë¶„
                context_parts.append(f"[[{source}]] {title} (p.{page})\n{text}")
            
            context = "\n\n".join(context_parts)
            
            system_prompt = """ë‹¹ì‹ ì€ ë²•ë¥  ë¬¸ì„œ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
1. ë°˜ë“œì‹œ ì•„ë˜ [ê²€ìƒ‰ëœ ì„¹ì…˜]ì˜ ë‚´ìš©ë§Œ ì‚¬ìš©í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.
2. ê° ì •ë³´ì˜ ëì— ë°˜ë“œì‹œ ì¶œì²˜ë¥¼ ëª…ì‹œí•˜ì„¸ìš”. í˜•ì‹: `(ë¬¸ì„œëª…, p.í˜ì´ì§€ë²ˆí˜¸)`
3. ë¬¸ì„œëª…ì€ íŒŒì¼ëª… ê·¸ëŒ€ë¡œ(í™•ì¥ì í¬í•¨) ì •í™•í•˜ê²Œ ê¸°ì¬í•˜ì„¸ìš”. ê¸¸ë”ë¼ë„ ìƒëµí•˜ì§€ ë§ˆì„¸ìš”.
4. ê²€ìƒ‰ëœ ì„¹ì…˜ì—ì„œ ë‹µì„ ì°¾ì„ ìˆ˜ ì—†ìœ¼ë©´ "ê²€ìƒ‰ëœ ë¬¸ì„œì—ì„œ í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."ë¼ê³  ë‹µí•˜ì„¸ìš”."""

            user_prompt = f"""[ê²€ìƒ‰ëœ ì„¹ì…˜]
{context}

[ì§ˆë¬¸]
{question}

[ë‹µë³€]"""

            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ]
            pageindex_answer = pageindex_rag.llm.generate(messages, thinking_effort="medium")
        else:
            pageindex_answer = "ê²€ìƒ‰ëœ ë¬¸ì„œì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        pageindex_time = time.time() - start
        
        final_answer = routing_log + pageindex_answer
        
        results["pageindex"] = {
            "answer": final_answer,
            "time": pageindex_time,
            "docs_searched": len(selected_docs)
        }
    except Exception as e:
        results["pageindex"] = {"answer": f"âŒ ì˜¤ë¥˜: {str(e)}", "time": 0, "docs_searched": 0}
    
    progress(1.0, desc="ì™„ë£Œ!")
    
    # Format responses
    vector_output = f"**â±ï¸ {results['vector']['time']:.2f}ì´ˆ**\n\n{results['vector']['answer']}"
    
    pi_docs = results["pageindex"].get("docs_searched", 0)
    pageindex_output = f"**â±ï¸ {results['pageindex']['time']:.2f}ì´ˆ** ({pi_docs}ê°œ ë¬¸ì„œ ê²€ìƒ‰)\n\n{results['pageindex']['answer']}"
    
    # Comparison summary at the end
    comparison = f"""---
### ğŸ“Š ë¹„êµ ìš”ì•½
| í•­ëª© | Vector RAG | PageIndex RAG |
|:---|:---:|:---:|
| **ì‘ë‹µ ì‹œê°„** | {results['vector']['time']:.2f}ì´ˆ | {results['pageindex']['time']:.2f}ì´ˆ |
| **ë‹µë³€ ê¸¸ì´** | {len(results['vector']['answer'])} ì | {len(results['pageindex']['answer'])} ì |
"""
    
    # Save to history
    try:
        history[query_hash] = {
            "timestamp": datetime.now().isoformat(),
            "query": question,
            "selected_docs": list(docs_to_search),
            "vector_result": {
                "answer": results["vector"]["answer"],
                "time": results["vector"]["time"]
            },
            "pageindex_result": {
                "answer": results["pageindex"]["answer"],
                "time": results["pageindex"]["time"],
                "docs_searched": results["pageindex"].get("docs_searched", 0)
            }
        }
        save_history(history)
        print(f"âœ… ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {query_hash}")
    except Exception as e:
        print(f"âŒ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
        comparison += f"\n\nğŸš¨ **ë¡œê¹… ì‹¤íŒ¨**: {str(e)}"
    
    return vector_output, pageindex_output, comparison, gr.Dropdown(choices=get_recent_queries())


# Build Gradio UI with sidebar layout
with gr.Blocks(
    title="RAG ë¹„êµ í…ŒìŠ¤íŠ¸ v3",
    theme=gr.themes.Soft(
        primary_hue="blue",
        neutral_hue="slate",
    ),
    css="""
        body, .gradio-container {
            background-color: #1a1a1a;
            color: #e0e0e0;
        }
        .answer-box { 
            border: 1px solid #404040; 
            border-radius: 8px; 
            padding: 16px; 
            background: #2a2a2a;
            min-height: 200px;
            color: #e0e0e0;
        }
        .answer-box p {
            color: #e0e0e0 !important;
        }
        .sidebar { 
            background: #262626; 
            padding: 15px; 
            border-radius: 8px; 
            border: 1px solid #404040;
        }
        /* Markdown headers in Dark Mode */
        h1, h2, h3 { color: #ffffff !important; }
        
        /* Table styles for Dark Mode */
        table { border-color: #404040 !important; }
        th { background-color: #333333 !important; color: #ffffff !important; }
        td { background-color: #2a2a2a !important; color: #e0e0e0 !important; }
    """
) as app:
    
    with gr.Row():
        # ===== ì¢Œì¸¡ ì‚¬ì´ë“œë°”: ë¬¸ì„œ ì„ íƒ =====
        with gr.Column(scale=1, elem_classes=["sidebar"]):
            gr.Markdown("## ğŸ•’ ìµœê·¼ ì§ˆì˜")
            recent_queries_dropdown = gr.Dropdown(
                choices=get_recent_queries(),
                label="ì´ë ¥ ì„ íƒ",
                interactive=True
            )
            
            gr.Markdown("---")
            gr.Markdown("## ğŸ“ ë¬¸ì„œ ì„ íƒ")
            
            search_all_checkbox = gr.Checkbox(
                label="ğŸŒ ì „ì²´ ë¬¸ì„œ ê²€ìƒ‰",
                value=True,
                info="ëª¨ë“  ë¬¸ì„œì—ì„œ ê²€ìƒ‰"
            )
            
            pdf_multiselect = gr.Dropdown(
                choices=pdf_files,
                multiselect=True,
                label="ê°œë³„ ë¬¸ì„œ ì„ íƒ",
                info="ì „ì²´ ê²€ìƒ‰ í•´ì œ ì‹œ ì‚¬ìš©"
            )
            
            gr.Markdown("---")
            gr.Markdown(f"**ì¸ë±ìŠ¤ í˜„í™©**")
            gr.Markdown(f"- Vector: {len(pdf_files)}ê°œ")
            gr.Markdown(f"- PageIndex: {len(pageindex_cached)}ê°œ")
        
        # ===== ë©”ì¸ ì˜ì—­: ì§ˆë¬¸ & ë‹µë³€ =====
        with gr.Column(scale=3):
            gr.Markdown("# ğŸ” Vector RAG vs PageIndex RAG ë¹„êµ")
            
            # ì§ˆë¬¸ ì…ë ¥
            question_input = gr.Textbox(
                label="â“ ì§ˆë¬¸",
                placeholder="ì˜ˆ: ì¸ê³µì§€ëŠ¥ ê¸°ë³¸ë²•ì—ì„œ ì •ì˜í•˜ëŠ” ê³ ì˜í–¥ ì¸ê³µì§€ëŠ¥ì€ ë¬´ì—‡ì¸ê°€ìš”?",
                lines=2
            )
            
            # Dropdown event handler
            # Dropdown event handler with auto-execution
            def update_input(query):
                return query
            

            
            compare_btn = gr.Button("ğŸš€ ë¹„êµ ë¶„ì„ ì‹¤í–‰", variant="primary", size="lg")
            
            gr.Markdown("---")
            
            # ë‹µë³€ ì˜ì—­
            with gr.Row():
                with gr.Column():
                    gr.Markdown("### ğŸ“¦ Vector RAG")
                    vector_output = gr.Markdown(elem_classes=["answer-box"])
                
                with gr.Column():
                    gr.Markdown("### ğŸŒ² PageIndex RAG")
                    pageindex_output = gr.Markdown(elem_classes=["answer-box"])
            
            # ë¹„êµ ìš”ì•½ (ë§¨ ë§ˆì§€ë§‰)
            comparison_summary = gr.Markdown()
            
            # ì˜ˆì‹œ ì§ˆë¬¸
            gr.Markdown("---")
            gr.Markdown("### ğŸ’¡ ì˜ˆì‹œ ì§ˆë¬¸")
            example_questions = gr.Examples(
                examples=[
                    ["ì¸ê³µì§€ëŠ¥ ê¸°ë³¸ë²•ì˜ ì£¼ìš” ëª©ì ì€ ë¬´ì—‡ì¸ê°€ìš”?"],
                    ["ê³ ì˜í–¥ ì¸ê³µì§€ëŠ¥ì´ë€ ë¬´ì—‡ì¸ê°€ìš”?"],
                    ["ì¸ê³µì§€ëŠ¥ íˆ¬ëª…ì„± í™•ë³´ë¥¼ ìœ„í•´ ì–´ë–¤ ì¡°ì¹˜ê°€ í•„ìš”í•œê°€ìš”?"],
                    ["ì¸ê³µì§€ëŠ¥ ì˜í–¥í‰ê°€ëŠ” ì–¸ì œ ìˆ˜í–‰í•´ì•¼ í•˜ë‚˜ìš”?"],
                ],
                inputs=[question_input]
            )
    
    # Event handlers
    compare_btn.click(
        fn=compare_answers,
        inputs=[pdf_multiselect, search_all_checkbox, question_input],
        outputs=[vector_output, pageindex_output, comparison_summary, recent_queries_dropdown]
    )
    
    # Dropdown event handler (Moved here to avoid NameError)
    recent_queries_dropdown.change(
        fn=update_input, 
        inputs=recent_queries_dropdown, 
        outputs=question_input
    ).then(
        fn=load_cached_result,
        inputs=[recent_queries_dropdown],
        outputs=[vector_output, pageindex_output, comparison_summary, recent_queries_dropdown]
    )


if __name__ == "__main__":
    print("\n" + "="*50)
    print("ğŸš€ RAG ë¹„êµ í…ŒìŠ¤íŠ¸ UI v3 ì‹œì‘")
    print("="*50)
    app.launch(
        server_name="127.0.0.1",
        server_port=7860,
        share=False,
        show_error=True
    )
