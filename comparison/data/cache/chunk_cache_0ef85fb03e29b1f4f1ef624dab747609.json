[
  {
    "text": " \n03 수명주기 전반에 걸친 위험관리\n53\n참고\n위험 방지 완화를 위한 사업자 조치 사례 (NIST AI 800-1 기반 재구성)\n[사이버 오용 위험 대응 예시]\n인공지능시스템이 악의적 사이버 활동(예: 악성코드 작성, 취약점 분석, 피싱 콘텐츠 자동 생성)을 지원하거나 \n자동화하는 데 오용될 수 있는 경우, 해당 시스템이 공격자에게 작용할 수 있는 전 단계별 기능을 분석하고 제어\n하는 위험 완화 방안을 마련한다. 이를 위해, 먼저 사이버보안 전문가 및 레드팀(red team)과 협력해 공격자 유형별 시나리오(예: 국가 기반 행위\n자, 사이버범죄조직, 해커팀 등)를 설정하고, 모델이 공격 준비, 실행, 확산 단계에서 어떠한 역할을 수행할 수 \n있는지를 구체적으로 분석한다.",
    "metadata": {
      "page": 53,
      "source": "2._260122_인공지능_안전성_확보_가이드라인.pdf",
      "chunk_index": 0,
      "chunk_method": "semantic_local"
    }
  },
  {
    "text": "이 분석은 사이버 킬체인 또는 TTP(Tactics, Techniques, Procedures) 체\n계를 참조. 이후, 악용 우려가 높은 기능(예: 자동화된 침투 스크립트, CTF 문제 해결 지원, 권한 상승 코드 작성 등)에 대해\n서는 출력 제한, 자동 거부 응답, 프롬프트 패턴 차단 알고리즘을 설계하고, 필요 시 모델의 기능 자체를 제거하거\n나 비활성화한다. 또한, 학습데이터에 오픈소스 취약점 정보, 해킹 툴 설명서 등이 포함되지 않도록 사전 정제 \n및 필터링 기준을 수립한다. 사업자는 API 또는 인터페이스 기반으로 모델을 제공하는 경우, 관련 기능에 대한 사용자 인증, 사용 이력 추적, \n장기 모니터링 체계를 마련해야 하며, 의심 사용자에 대해서는 자동 알림 및 제한 조치를 신속히 수행할 수 있어\n야 한다. 특히 위험이 높은 기능은 일반에 공개하지 않고, 보안 대응 주체에게 선제적으로 제공한 뒤 점진적 접근\n이 가능하도록 단계적 배포 전략을 채택한다. 사이버 오용 관련 징후가 실제 운영 중에 발생한 경우, 사업자는 즉시 오용 정황을 탐지 䞻 기록 䞻 차단하고, 외부 \n전문가 또는 유관기관에 통보함으로써 사후적 대응을 병행해야 한다. 이와 더불어, 실사용 사례, 유사기업의 운영 \n경험 등을 분석해 위험 관리 절차를 지속적으로 갱신할 수 있는 적응형 방어 체계를 갖추는 것이 바람직하다. ",
    "metadata": {
      "page": 53,
      "source": "2._260122_인공지능_안전성_확보_가이드라인.pdf",
      "chunk_index": 1,
      "chunk_method": "semantic_local"
    }
  }
]