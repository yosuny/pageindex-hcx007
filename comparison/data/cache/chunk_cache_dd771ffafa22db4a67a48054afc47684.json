[
  {
    "text": "표시 방법\n25\nl 학술 및 콘텐츠 윤리 문제\n- 생성형 인공지능이 학술논문, 자기소개서, 기사, 논문에 사용하는 그림 등을 생성하여 활용하는 \n사례가 증가하면서 공동 저자로 등록하고, 서로 다른 논문임에도 유사한 그림, 글이 무분별하게 양산\n| 생성형 인공지능의 AI 표절 |\n사건\n내용\n네이처, 인공지능 활용 논문 \n검증에 대한 주의(’24년 11월)\n‘Frontiers in Cell and Developmental Biology’에 실렸던 한 논문을 \n소개하면서 터무니없이 큰 생식기를 지닌 쥐 이미지가 사용됐는데 알고 \n보니 생성형 이미지 모델 ‘미드저니’로 만든 것으로 밝혀져 철회된 사례를 \n집중하며 인공지능을 논문에 활용하는 것을 우려\n턴잇인, AI 논문 표절 심각성 \n발표(’24년 4월)\n온라인 표절 검사 서비스(Turnitin) 기업은 ’23년 4월 이후 플랫폼 제출 \n2억개 논문 중 약 11%가 표절이라고 발표\n➽ 사례 예시(공동 저자로 ChatGPT가 등장한 논문이 게재되면서 과학계 반발)\n과학기술 저널에 등재된 공동 저자 ‘ChatGPT’\n- ChatGPT가 2023년 한해 책/저널을 발표하여 저작권을 보유하고 있는 경우 200여 권이 확인, \n네이처의 발표에 따르면 최소 4편 이상이 연구논문에 공동 저자로 등록\n- (과학계) ChatGPT가 공동 저자로 등록하는 것이 표절 문제를 동반한다면 최소한의 윤리 지침을 \n지켜야 한다고 지적하며 네이처 등에서는 저자로서 인정 불가 의사 표시\n과학계 반발에 관한 다양한 기사\n",
    "metadata": {
      "page": 29,
      "source": "1._260126_인공지능_투명성_확보_가이드라인.pdf",
      "chunk_index": 0,
      "chunk_method": "semantic_local"
    }
  }
]