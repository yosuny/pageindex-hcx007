[
  {
    "text": "43\n안전한 설계 및 개발\n3-1-2. 개발사업자\n목표\n이용자 보호를 위해 인공지능을 안전하게 설계 및 개발해야 함. 설명\n개발사업자는 인공지능의 안전성 확보를 위해 노력해야 함. 안전성인공지능이 판단예측한 결과로 시스템이 동작하거나 기능이 수행됐을 때 사람과 환경에 위험을 \n- \n: \n·\n줄 가능성이 완화 또는 제거된 상태 출처신뢰할 수 있는 인공지능 개발안내서\n(\n: \n)\n시스템 오류 혹은 오작동 발생 시 안전하게 정지하거나 최소한의 기능만 유지할 수 있도록 기술적 조치를 \n- \n마련할 수 있음. 위험 대응력을 향상시키기 위해 오류탐지\n비상정지기능 등을 포함할 수 있으며관련 내용은 \n- \n‘\n’, ‘\n’ \n, \n4-1-2 \n사람의 개입 방법참고\n‘\n’ \n. 개발사업자는 인공지능의 견고성 확보를 위해 노력해야 함. 견고성\n인공지능이 외부의 간섭이나 극한적인 운영 환경 등에서도 사용자가 의도한 수준의 성능 및 \n- \n: \n기능을 유지하는 상태 출처신뢰할 수 있는 인공지능 개발안내서\n(\n: \n)\n- 의도치 않은 입력으로 인한 오작동을 방지하기 위해 입력값 유효성 검증 등의 기술적 조치를 마련할 수 있음. 악의적인 공격비정상 데이터 입력 등의 예측 불가능한 상황에 대응할 수 있도록 적대적 공격에 대한 방어 \n- \n, \n능력을 강화하기 위해 노력해야 함. 참고\n\n신뢰할 수 있는 인공지능 개발안내서\n韓 \n세부요구사항 \n데이터 공격에 대한 방어 수단을 강구하였는가\n- \n06-2. ? 요구사항 \n인공지능 모델 공격에 대한 방어 대책 수립\n- \n10. 세부요구사항 \n모델 공격이 가능한 상황을 파악하였는가\n- \n10-1. ? 세부요구사항 \n모델 공격에 대한 방어 수단을 강구하였는가\n- \n10-2.",
    "metadata": {
      "page": 44,
      "source": "4._260122_고영향_인공지능_사업자_책무_가이드라인-1.pdf",
      "chunk_index": 0,
      "chunk_method": "semantic_local"
    }
  },
  {
    "text": "? \nNIST AI RMF\n美 \n- MANAGE 2.4: 목적 외 결과에 대한 대응을 위해 인공지능 시스템 대체해제 또는 비활성화 메커니즘 마련\n, \nEU AI ACT\n제\n조인공지능 시스템의 의도된 목적성능위험 등을 포함한 명확한 사용 지침 제공\n- \n13\n: \n, \n, \n제\n조정확도 및 견고성을 위해 측정 방법 및 복원력 확보 방안 정의\n- \n15\n: \n전문\n인공지능 시스템은 안전성투명성다양성 등을 고려하여 설계\n- \n(recital) 27: \n, \n, \n사업자 구분\n자가점검\n개발 단계에서 오류탐지 및 비상정지 등 사람의 개입이 가능하도록 기술적 조치를 \n마련하였는가? 인공지능 모델 자체의 취약점학습 데이터 오염시스템 접근 등과 관련된 잠재적 보안 \n, \n, \n위협 요소를 점검하고 대응책을 마련하였는가? 개발     \n \n개발 \n \n \n",
    "metadata": {
      "page": 44,
      "source": "4._260122_고영향_인공지능_사업자_책무_가이드라인-1.pdf",
      "chunk_index": 1,
      "chunk_method": "semantic_local"
    }
  }
]