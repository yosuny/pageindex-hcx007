[
  {
    "text": "4\n가이드라인 적용 방법\n1.2 \n본 절에서는 국내외 주요 기준과의 연계성을 토대로 이해관계자별 적용 방식과 활용 방안을 제시한다\n고영향 인공\n. 지능의 사회적 파급력을 고려하여\n다양한 이해관계자가 각자의 역할에 따라 이를 효과적으로 적용할 수 있도록 구\n, \n성하였으며\n기술적정책적 지원 체계를 포함하여 실질적인 이행 가능성을 제고하고자 한다\n, \n·\n. 이를 위해 우선 본 가이드라인의 제정 과정에서 국내외 주요 인공지능 관련 정책 및 표준 문서를 심층적으로 분석하\n고그 핵심 원칙과 내용을 본 가이드라인에 반영하였다특히한국정보통신기술협회\n의 신뢰할 수 있는 인공지능 \n, \n. , \n(TTA)\n개발 안내서\n미국 국립표준기술연구소\n의 인공지능 위험 관리 프레임워크\n, \n(NIST)\n(AI Risk Management Framework, \n유럽연합\n의 인공지능 법\n은 아래와 같은 이유로 주요 참조 문서로써 활용하였다\nAI RMF), \n(EU)\n(AI Act)\n. 국내 환경 및 기술적 특성 고려\n신뢰할 수 있는 인공지능 개발 안내서\n1.",
    "metadata": {
      "page": 5,
      "source": "4._260122_고영향_인공지능_사업자_책무_가이드라인-1.pdf",
      "chunk_index": 0,
      "chunk_method": "semantic_local"
    }
  },
  {
    "text": ": TTA \n신뢰할 수 있는 인공지능 개발 안내서는 국내 환경과 기술적 특성을 고려하여 신뢰할 수 있는 인공지능 개발 \nTTA \n및 활용을 위한 실무적인 지침을 제공한다\n이는 국내 사업자들이 인공지능을 개발하고 운영하는 과정에서 직면하는 \n. 특수한 상황과 요구사항을 반영하는 데 매우 중요하다. 실무적이고 구체적인 지침:\n안내서는 인공지능 개발의 전 단계에 걸쳐 고려해야 할 기술적 요구사항을 구체적으로 \n TTA \n제시한다예를 들어데이터 수집 및 처리인공지능 모델 개발시스템 구현운영 및 모니터링 단계별로 신뢰성 확보를 \n. , \n, \n, \n, \n위한 체크리스트나 권장 사항을 포함하고 있다이러한 실무적인 내용은 본 가이드라인이 추상적인 원칙 나열에 그치지 \n. 않고사업자들이 실제 업무에 적용할 수 있는 실질적인 방안을 제시하는 데 크게 기여한다\n, \n. 국내 기술 및 산업 환경 반영:\n는 국내 \n표준화를 선도하는 기관으로서국내 인공지능 기술 수준산업 구조\n TTA\nICT \n, \n, \n, \n그리고 규제 환경을 가장 잘 이해하고 있다\n안내서를 참조함으로써 본 가이드라인은 국내 사업자들의 현실적인 \n. TTA \n역량과 상황을 고려한 책임 기준을 제시할 수 있다이는 사업자들의 수용성을 높이고가이드라인의 실효성을 확보하는 \n. , \n데 필수적이다. 국내 인공지능 윤리 원칙과의 연계:\n안내서는 대한민국 정부가 제시한 인공지능 윤리 기준을 기반으로 하고 있으며\n TTA \n'\n'\n, \n이를 기술 개발 및 적용의 관점에서 구체화한 문서이다본 가이드라인이 \n안내서를 참조함으로써정부의 인공지능 \n. TTA \n, \n정책 방향과 일관성을 유지하고\n국내 사회가 지향하는 인공지능 윤리 가치를 사업자책무에 효과적으로 반영할 수 \n, \n있습다이는 인공지능이 사회적 신뢰를 얻고 지속적으로 발전하는 데 필요한 국내적 합의를 형성하는 데 기여할 것이다\n. .",
    "metadata": {
      "page": 5,
      "source": "4._260122_고영향_인공지능_사업자_책무_가이드라인-1.pdf",
      "chunk_index": 1,
      "chunk_method": "semantic_local"
    }
  },
  {
    "text": "포괄성과 범용성\n의 위험 관리 접근 방식\n2. : NIST AI RMF\n는 인공지능 시스템의 전 수명주기에 걸쳐 발생하는 잠재적 위험을 식별\n평가\n완화 및 관리하기 위\nNIST AI RMF\n, \n, \n한 포괄적인 프레임워크를 제공한다\n이 프레임워크는 특정 기술이나 산업에 국한되지 않고\n모든 유형의 인공지능 \n. , \n시스템에 적용될 수 있는 범용성을 지니고 있다. 위험 기반 접근의 체계화:\n는 인공지능의 위험을 분류하고\n위험 수준에 따른 차등적인 관리 방안을 \n NIST AI RMF\n, \n제시함으로써사업자들이 인공지능 시스템의 특성과 잠재적 영향에 따라 합리적이고 효율적인 위험 관리를 수행할 수 \n, \n있도록 돕는다이는 본 가이드라인이 사업자들에게 실질적인 지침을 제공하고불필요한 규제 부담을 최소화하면서도 \n. , \n책임 있는 인공지능 개발 및 활용을 유도하는 데 필수적인 요소이다. 다양한 이해관계자의 참여 유도:\n는 인공지능 위험 관리가 기술 개발자사용자규제 기관 등 다양한 \n NIST AI RMF\n, \n, \n이해관계자의 협력을 통해 이루어져야 함을 강조한다\n이는 본 가이드라인이 제시하는 사업자책무가 단순히 기술적 \n. 측면에 머무르지 않고사회적 맥락에서의 인공지능 윤리와 신뢰성을 확보하는 데 기여할 수 있도록 한다투명성설명 \n, \n. , \n가능성공정성 등 핵심적인 인공지능 윤리 원칙들이 위험 관리의 관점에서 구체적으로 적용될 수 있는 토대를 제공한다\n, \n. 자발적 채택 및 유연성:\n는 강제적인 규제가 아닌 자발적인 채택을 장려하며조직의 특성과 상황에 맞게 \n NIST AI RMF\n, \n",
    "metadata": {
      "page": 5,
      "source": "4._260122_고영향_인공지능_사업자_책무_가이드라인-1.pdf",
      "chunk_index": 2,
      "chunk_method": "semantic_local"
    }
  }
]