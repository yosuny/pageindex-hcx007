[
  {
    "text": "인공지능 투명성 확보 가이드라인\n24\nl 디지털 성범죄\n- 생성형 인공지능을 오남용하여 성적 허위 영상물(성착취물)을 제작 및 유포하는 행위가 발생하고 \n있으며, 연예인이나 지인의 얼굴을 음란물과 합성해 유포하는 디지털 성범죄가 빈번히 발생\n- 이미지의 유포･합성･소비의 가능성을 무한대로 확장시키기 때문에 디지털 성범죄는 피해와 가해의 \n구도가 1대 N을 이루고, 생산자와 소비자의 경계가 불분명6)\n| 딥페이크 기술을 활용한 디지털 성범죄 사례 |\n기간\n내용\n2024년 9월 ~\n서울의 한 고등학교에 다니는 학생들 사이에선 최근 주변 4개 고교에 재학 중인 남학생 \n5명이 동료 여학생 10여 명의 사진을 불법 합성\n2024년 8월 ~\n텔레그램 단체 채팅방에서 현역 군인들이 여성 동료 군인들의 얼굴 사진을 딥페이크 \n방식으로 합성해 성착취물을 제작 및 공유\n➽ 사례 예시(생성형 인공지능 활용 아동 성착취물 제작자 기소)\n생성형 인공지능 활용 아동 성착취물 제작자 기소7)\n- 2023년 4월, 생성형 인공지능 서비스에 ‘나체’, ‘어린이’ 등의 텍스트를 입력하여 360개의 아동 성착취물을 \n제작한 사건이 발생\n- 우리나라 법원에서는 해당 행위가 아동･청소년의 성보호에 관한 법률에 위반되었다고 판시하여 징역 2년 \n6개월이 선고\n- 피고인은 유포할 목적이 없었고, 가상의 이미지를 가지고 있는 것은 처벌 대상이 아니라고 생각했다고 진술\n했으나 재판부는 피해자가 없다고 해도 성적 표현물 자체가 명백하게 아동으로 인식될 수 있다면 아동\n청소년보호법 위반에 해당할 수 있다고 판시\n6) 디지털 성범죄의 특징 및 현황, 찾기 쉬운 생활법령 정보(법제처),\nhttps://www.easylaw.go.kr/CSP/CnpClsMain.laf?csmSeq=1594&ccfNo=1&cciNo=1&cnpClsNo=2\n7) AI 프로그램으로 아동 성 착취물 제작해 구속 기소, KBS 뉴스, https://news.kbs.co.kr/news/pc/view/view.do?ncd=7738404\n",
    "metadata": {
      "page": 28,
      "source": "1._260126_인공지능_투명성_확보_가이드라인.pdf",
      "chunk_index": 0,
      "chunk_method": "semantic_local"
    }
  }
]