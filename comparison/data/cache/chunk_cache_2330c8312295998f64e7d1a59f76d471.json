[
  {
    "text": "인공지능 안정성 확보 가이드라인\n62\n인공지능 안정성 확보 가이드라인\n- 인공지능 안전사고 모니터링 및 대응체계의 구축䞻운영 현황\n- 관련 조직, 절차, 문서화 및 관리 체계\n• 각 항목은 실제 이행 여부와 수준을 확인할 수 있도록 구체적으로 기술. • 다만, 영업비밀 등 다른 법령에 따라 보호되는 정보는 해당 범위 내에서 제출 대상에서 제외\n(4) 제출 전 내부 검토 및 승인\n• 안전성 확보 조치 결과 제출은 사업자의 공식적 책임 행위에 해당하므로, 제출 전에 내부 검토 및 승인 \n절차 필요\n• 내부 검토 과정에서는 다음 사항을 점검:\n- 제출 내용의 사실성 및 최신성\n- 고시상 책무와의 대응 관계\n- 문서화의 충실도 및 근거 자료의 존재 여부\n• 필요 시 법무䞻기술䞻정책䞻경영 부문 간 교차 검토를 통해 제출 문서의 정확성과 책임성을 확보\n(5) 제출 형식 및 제출 이후 관리\n• 제출 문서는 체계적인 양식에 따라 작성䞻제출\n• 제출 이후에도 해당 문서와 근거 자료는 특정 사유로 인한 추가 제출 또는 안전사고 보고에 대비하여 \n체계적으로 보관䞻관리\n<자가점검 체크리스트> \n□ 해당 인공지능이 제3조제1항에 해당함을 인지한 시점과 근거가 내부적으로 기록되어 있는가? □ 적용 대상 인지일을 기준으로 3개월 이내 제출 기한이 관리되고 있는가? □ 제출 문서에 제4조부터 제7조까지의 안전성 확보 조치가 모두 반영되어 있는가? □ 제출 전 내부 검토 및 승인 절차가 실질적으로 이루어졌는가? □ 제출 문서가 공식 양식과 지정된 제출 경로를 준수하고 있는가? □ 제출 이후 추가 보고나 사고 보고에 대비한 문서 관리 체계가 마련되어 있는가?",
    "metadata": {
      "page": 62,
      "source": "2._260122_인공지능_안전성_확보_가이드라인.pdf",
      "chunk_index": 0,
      "chunk_method": "semantic_local"
    }
  },
  {
    "text": "1-2. 특정 사유로 인한 추가 제출\n[목표] 인공지능의 실질적 변경 또는 새로운 위험의 발생䞻예상이 확인된 경우, 기존에 제출한 안전성 확보 \n조치의 적정성을 재점검하고 변경된 위험 수준을 반영한 추가 조치 이행 결과를 과학기술정보 \n통신부장관에게 적시에 제출\n",
    "metadata": {
      "page": 62,
      "source": "2._260122_인공지능_안전성_확보_가이드라인.pdf",
      "chunk_index": 1,
      "chunk_method": "semantic_local"
    }
  }
]