[
  {
    "text": "인공지능 안정성 확보 가이드라인\n32\n인공지능 안정성 확보 가이드라인\n| 주요, 권장, 선택 방법론 예시 |\n주요 방법론\n권장 방법론\n선택 방법론\n• 관리 후보 위험 목록: EU의 AI법 \n「범용인공지능 실천강령(Code of \nPractice)」에서 규정한 4대 위험 \n(사이버공격, 화생방, 대규모 조작, \n통제 상실) 등 사전 정의된 위험 \n체크리스트 \n• 위험 분류체계(Taxonomy): 「국제 AI \n안전 보고서」의 구조화된 위험 분류 \n체계\n• 개발 초기: 유사 모델 참조(기존 \n유사 AI의 위험 사례 활용), \n시나리오 분석(미래 위험 \n시나리오 예측)\n• 배포 전: 레드팀 테스트(악의적 \n공격 시뮬레이션), 위협 \n모델링(체계적 취약점 식별)\n• 운영 중: 시스템 모니터링(실시간 \n위험 탐지), 오용 사례 분석(실제 \n악용 패턴 파악)\n• 모델 능력 경계 테스트: 특정 \n임계값 초과 여부 평가 (프론티어 \nAI 해당)\n• 전문가 협력: 외부 전문가 집단의 \n통찰 활용 (고영향 인공지능시스템)\n• 델파이 기법: 반복 설문을 통한 \n전문가 합의 도출 (복잡한 위험)\n(3) 개발 단계䞻운영 단계별 방법론의 차별적 적용\n• 위험 식별 방법론은 인공지능의 개발 단계와 운영 단계에 따라 달리 적용하는 것이 효과적:\n- 개발 초기 단계에서는 유사 인공지능 사례 분석이나 시나리오 분석을 통해 구조적䞻장기적 위험을 \n탐색\n- 배포 전 단계에서는 레드팀 테스트나 위협 모델링을 통해 악의적 공격 가능성과 취약점을 집중적 \n으로 점검\n- 운영 단계에서는 시스템 모니터링과 실제 오용 사례 분석을 통해 예상하지 못한 위험을 조기에 탐지\n• 이러한 단계별 적용은 위험 식별을 일회적 점검이 아닌 동적인 순환 과정으로 만드는 데 기여\n(4) 최소 기준 설정과 절차 운영의 유연성 확보\n• 고시의 취지에 부합하도록, 사업자는 위험 식별 절차와 방법에 대해 최소한의 운영 기준을 명확히 \n설정. 예컨대 절차의 단계 구성, 적용 방법론 수, 정기 갱신 주기 등이 이에 해당\n• 동시에 인공지능 기술의 급속한 발전과 새로운 위험 유형의 출현을 고려하여, 기존 절차나 방법론을 \n경직되게 고정하지 않고 필요 시 신속히 보완䞻확장할 수 있는 유연성을 확보\n• 이를 위해 분기별 또는 주기적으로 위험 식별 절차와 방법론의 적절성을 재검토\n(5) 책임과 역할의 명확화\n• 위험 식별 절차가 형식적으로 운영되지 않도록, 각 단계별 책임 부서와 담당자, 의사결정 권한을 \n명확히 정의\n• 특히 위험 식별 결과가 이후 위험 평가 및 위험 완화 단계로 어떻게 연계되는지에 대한 내부 흐름을 \n명확히 함으로써, 절차 간 단절을 방지\n",
    "metadata": {
      "page": 32,
      "source": "2._260122_인공지능_안전성_확보_가이드라인.pdf",
      "chunk_index": 0,
      "chunk_method": "semantic_local"
    }
  }
]