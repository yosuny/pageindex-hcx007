[
  {
    "text": " \n01 개요\n9\n제2조(정의) 이 고시에서 사용하는 용어의 뜻은 다음과 같다. 1. “위험”이란 인공지능 수명주기 전반에 걸쳐, 사람의 생명䞻신체의 안전 또는 기본권이 침해될 \n가능성과 그 잠재적 피해의 심각성을 말한다. 2. “누적연산량”이란 인공지능 학습에 사용된 총 연산량을 말하며, 부동소수점연산(Floating Point \nOperations, FLOPs)으로 표기한다. 3. “인공지능 수명주기”란 인공지능의 개발, 배포, 운영 및 폐기에 이르기까지의 전 과정을 말한다. 4. “인공지능 관련 안전사고”란 인공지능의 장애 등으로 인하여 위험이 현실적으로 발생하거나 공공의 \n안전에 중대한 위해가 발생한 경우를 말한다. 5. “위험관리체계”란 인공지능 관련 안전사고를 모니터링하고 대응하는 책임 주체의 권한과 의무 등을 \n규정한 체계를 말한다. 제3조(적용 대상)\n① 「인공지능 발전과 신뢰 기반 조성 등에 관한 기본법」(이하 “법”이라고 한다) 제32조제2항에 따라 이행 \n결과를 제출하여야 하는 인공지능사업자는 다음 각 호와 같다. 1. 인공지능이 개발되어 타인에게 제공되는 시점부터 「인공지능 발전과 신뢰 기반 조성 등에 관한 \n기본법 시행령」(이하 “영”이라고 한다) 제24조제1항에 따른 인공지능에 해당한 경우 : 해당 \n인공지능을 개발한 인공지능개발사업자\n2. 영 제24조제1항에 해당하지 않는 인공지능에 대해 실질적으로 변경을 가하여 이에 해당하게 한 \n경우 : 해당 변경을 가한 인공지능사업자\n② 영 제24조제2항에 따른 누적연산량은 인공지능 학습 과정에서 기록된 데이터 및 시스템 로그 등 객관적 \n지표를 활용하여 산출하되, 데이터 전처리, 미세조정 등 모든 학습 관련 연산량을 포괄적으로 반영하여 \n산출한다. 단, 사전 단계의 연산 등 실제 인공지능의 능력 향상에 실질적인 기여가 없었던 연산은 \n누적연산량에서 제외할 수 있다.",
    "metadata": {
      "page": 9,
      "source": "2._260122_인공지능_안전성_확보_가이드라인.pdf",
      "chunk_index": 0,
      "chunk_method": "semantic_local"
    }
  },
  {
    "text": "③ 영 제24조제2항에 따른 누적연산량의 대표적인 산정 방식은 다음과 같다. 1. 인공지능의 설계 정보나 구조를 바탕으로 수학적으로 연산량을 추정하는 이론적 산정 방식\n2. 관찰된 경험적 수치에 기반해 일부 지표로 연산량을 계산하는 경험적 䞻 통계적 산정 방식\n3. 하드웨어 자원의 실제 사용량을 기반으로 연산량을 계산하는 하드웨어적 산정 방식\n④ 과학기술정보통신부장관은 필요한 경우 인공지능사업자가 제출한 누적 연산량 관련 자료의 검증을 \n인공지능사업자의 동의를 받아 전문기관에 의뢰할 수 있다. ",
    "metadata": {
      "page": 9,
      "source": "2._260122_인공지능_안전성_확보_가이드라인.pdf",
      "chunk_index": 1,
      "chunk_method": "semantic_local"
    }
  }
]