[
  {
    "text": " \n03 수명주기 전반에 걸친 위험관리\n29\n• 인공지능의 기능적 오류 및 데이터 편향 가능성, 보안 취약점 등 기술적 특성:\n- 기능적 오류, 데이터 편향, 보안 취약점과 같은 기술적 한계와 취약점은 인공지능 전반에 공통적 \n으로 나타날 수 있는 주요 위험 요소로서, 체계적인 검토 대상에 포함\n| 위험 요소의 정의, 설명, 예시 |\n위험 요소\n정의 및 설명\n예시\n① 기능적 오류 \n(Functional \nFailures)\n• 인공지능 시스템이 의도한 방식으로 \n작동하지 않거나, 예측 성능이 허용 \n가능한 수준을 벗어난 상태\n• 과도한 환각, 목표 설정 오류, \n설명불가능한 의사결정\n② 데이터 편향 \n(Data Bias)\n• 학습 또는 평가에 사용된 데이터가 \n불균형하거나 특정 집단에 편향된 정보를 \n포함하는 상태\n• 얼굴 인식 모델의 인종 편향, 언어 모델의 \n성별 고정관념 재생산\n③ 보안 취약점 \n(Security \nVulnerabilities)\n• 외부 또는 내부 위협자에 의해 시스템이 \n침해될 수 있는 기술적 약점\n• 적대적 공격, 모델 추출, 백도어 삽입, \n무단 접근\n④ 악용 가능성 \n(Misuse Potential)\n• 시스템의 설계 의도와 달리 악의적 목적 \n또는 비정상적 방식으로 사용될 위험\n• 사이버 공격 자동화, 생물학적 무기 설계 \n지원, 정치적 조작 캠페인 등\n• 인공지능의 오남용 및 악용 가능성:\n- 인공지능은 본래의 설계 목적과 달리 사용되거나 악의적으로 활용될 수 있으므로, 사업자는 이를 \n합리적으로 예상 가능한 범위에서 위험 식별 대상에 포함\n- 오남용의 예로는 비전문가가 의료䞻법률 분야 인공지능의 결과를 그대로 활용하여 발생하는 피해가 \n있으며, 악용의 예로는 딥페이크를 이용한 신원 도용, 자동화된 피싱 공격, 허위정보의 대규모 확산 \n사례 존재\n- 이러한 위험은 최근 발생 사례의 존재 여부, 기술적 실행 용이성, 경제적䞻사회적 유인의 존재 여부 \n등을 종합적으로 고려하여 식별\n- 발생 가능성이 극히 낮거나 실행이 사실상 불가능한 시나리오는 제외할 수 있으나, 이미 유사 사례가 \n존재하거나 공개 도구를 통해 비교적 손쉽게 실행 가능한 경우에는 반드시 위험 후보로 포함\n<자가점검 체크리스트>\n□ 위험 식별의 범위를 인공지능 수명주기 전 과정으로 설정하고, 단계별 위험 후보를 검토하였는가? □ 객관적 근거에 기반하여 \"합리적으로 예상 가능한 범위\"를 설정하였는가?",
    "metadata": {
      "page": 29,
      "source": "2._260122_인공지능_안전성_확보_가이드라인.pdf",
      "chunk_index": 0,
      "chunk_method": "semantic_local"
    }
  },
  {
    "text": "□ 인공지능의 특수성과 기술적 특성을 함께 고려하여 위험을 식별하였는가? □ 합리적으로 예상 가능한 오남용䞻악용 시나리오를 포함하여 위험을 식별하였는가? □ 식별된 위험을 현존/잠재로 구분하고, 발생 조건䞻영향 경로 등 핵심 맥락 정보를 함께 정리하였는가? ",
    "metadata": {
      "page": 29,
      "source": "2._260122_인공지능_안전성_확보_가이드라인.pdf",
      "chunk_index": 1,
      "chunk_method": "semantic_local"
    }
  }
]