[
  {
    "text": " \n02 적용 대상 및 의무 주체 판단\n17\n연산량을 추정하는 방식이다. 단점으로는 경험적 계수가 모델마다 다를 수 있고, 비공개 모델에는 적용에 한계\n C = 6 × N(파라미터 수) × D(토큰 수)\n| 스케일링 법칙 기준 계산 사례 |\n대상 모델\n계산결과\n측정기관(연구진)\nGPT-3\n𝑁=1.75×1011, 𝐷=3×1011\nC ≈ 3.15×1023䞱FLOPs\nO社\nLlama3 400B \n𝑁= 4 × 1011, 𝐷=1.5 × 1013 \nC ≈ 3.6×1025 FLOPs\nAndrej Karpathy\n- (시퀸스 기반 방식) 보다 정밀한 추정 방식으로 시퀀스 단위의 실제 연산량과 입력 길이를 기반으로 하며, \n모델의 구조적 효율성과 데이터 사용 균형을 반영한 연산량을 추정. 이는 시퀀스당 부동소수점연산 수, \n토큰 수, 시퀀스 길이 등을 변수로 활용\n C = 3 × (시퀸스당 부동소수점연산 수) × D(토큰 수) / n_ctx(시퀸스 길이)\n[GPU 사용량 기반 추정식] 가장 실측에 가까운 방식으로 GPU 또는 TPU와 같은 하드웨어 자원의 실제 사용량을 \n기반으로 연산량을 계산하는 방식\n- (단일 GPU 장비 기반 방식) GPU의 초당 연산 성능(FLOPs/s)에 실제 사용 시간을 곱해 총 연산량을 산출.",
    "metadata": {
      "page": 17,
      "source": "2._260122_인공지능_안전성_확보_가이드라인.pdf",
      "chunk_index": 0,
      "chunk_method": "semantic_local"
    }
  },
  {
    "text": "단순하면서도 실행 기록만 확보하면 정확도가 높은 방식\n C = 𝜏(GPU 또는 TPU 성능, FLOPs/s) × 𝑇(총 사용시간) \n- (다중 GPU 장비 기반 방식) 전체 학습 시간, 사용된 GPU 또는 TPU 수, 각 장비의 최대 FLOPs/s 성능, \n그리고 평균 가동률을 모두 고려해 총 연산량을 계산하는 방식\n C = 학습시간 × GPU 또는 TPU 수 × 1대당 최대 FLOPs/s × 평균 가동률 \n[보조적 방법] 위에서 제시한 방식 외에도 합리적인 연산량 추정을 위한 다양한 보조적 방법이 존재\n- 예를 들어, 클라우드 서비스 제공업체의 사용량 기반 과금 정보, 실행 로그나 시스템 모니터링 툴, 또는 \n단위 전력당 연산량을 기준으로 하는 에너지 사용 기반 추정 등이 있다. 이러한 방식은 직접 측정이 어려운 \n경우 간접적인 수단으로 활용 가능\n",
    "metadata": {
      "page": 17,
      "source": "2._260122_인공지능_안전성_확보_가이드라인.pdf",
      "chunk_index": 1,
      "chunk_method": "semantic_local"
    }
  }
]