[
  {
    "text": " \n03 수명주기 전반에 걸친 위험관리\n33\n<자가점검 체크리스트> \n□ 위험 식별을 위한 단계적 절차가 마련되어 있는가? □ 개발䞻배포䞻운영 단계별로 적절한 위험 식별 방법론을 차별적으로 적용하고 있는가? □ 필수 방법론을 포함하여 최소 2개 이상의 위험 식별 방법론을 병행하고 있는가? □ 위험 식별 결과에 대한 내부 검증 또는 교차 검토 절차가 마련되어 있는가? □ 위험 식별 절차와 방법론을 정기적으로 재검토䞻갱신하고 있는가? 참고\n위험 식별 방법론\n관리 후보 위험 목록은 사전에 정의된 위험 요소들을 목록화해 체크리스트처럼 활용하는 방식이다. EU AI법 \nGPAI CoP가 대표적인 예로, 고도화된 인공지능 모델 특유의 위험, 대규모 영향, 빠른 전개, 회복 불가능의 특징\n을 가진, 반드시 고려해야 할 4가지 위험 유형(①사이버 공격 위험 ②화생방 위험 ③유해한 대규모 조작 ④통제 \n상실 위험)을 제시하고 있다. 위험 분류체계(Taxonomy) 역시 유사한 접근으로, 『2025 국제 AI 안전 보고서』에서는 구조화된 위험 분류를 \n통해 체계적인 위험 관리를 가능하게 한다. 유사 능력 모델 이용 방법론은 기존에 개발된 유사한 인공지능 모델의 위험을 참고해 새로운 모델의 위험을 예측\n하는 방식이다. NIST RMF 에서는 이러한 접근을 통해 효율적인 위험 식별을 권고한다. 모델 능력 경계 평가(Threshold Evaluation)는 인공지능 모델의 능력이 특정 임계값을 초과하는지 평가해 위\n험을 식별하는 방법으로, 예를 들면, AI 서울 정상회의 「프론티어 인공지능안전 서약(Frontier AI Safety \nCommitment)」 등에서 도입하고 있다. 위협 모델링은 전통적인 사이버보안 분야에서 차용한 방법론으로, 체계적인 위협과 취약점 식별 절차를 인공지\n능 모델에 적용한다. NIST RMF에서는 이를 인공지능 모델의 특성에 맞게 조정해 제시하고 있다. 시나리오 분석은 미래에 발생 가능한 위험 시나리오를 예측하고 분석하는 방법으로, 주요 인공지능 사업자들이 \n장기적 인공지능 안전성 평가에 적극 활용하고 있다. 전문가 䞻 커뮤니티 협력은 다양한 분야의 전문가들과 협업해 위험을 식별하는 방식으로, EU AI법 GPAI CoP와 \nG7 「히로시마 프로세스」에서 강조되고 있다. 델파이 기법은 전문가 집단의 반복적인 설문을 통해 합의를 도출하는 구조화된 방법론으로, 『2025 국제 AI 안전 \n보고서』작성 과정에서 활용되었다. 오용 사례 분석은 인공지능시스템의 악의적 사용 가능성을 체계적으로 분석하는 방법이다.",
    "metadata": {
      "page": 33,
      "source": "2._260122_인공지능_안전성_확보_가이드라인.pdf",
      "chunk_index": 0,
      "chunk_method": "semantic_local"
    }
  },
  {
    "text": "NIST RMF 등에서\n는 이를 통해 잠재적 위험을 사전에 식별한다. ",
    "metadata": {
      "page": 33,
      "source": "2._260122_인공지능_안전성_확보_가이드라인.pdf",
      "chunk_index": 1,
      "chunk_method": "semantic_local"
    }
  }
]