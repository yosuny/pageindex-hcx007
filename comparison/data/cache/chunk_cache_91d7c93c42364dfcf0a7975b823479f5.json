[
  {
    "text": "9\n제호안전성신뢰성 확보를 위한 조치의 내용을 확인할 수 있는 문서의 작성과 보관\n5\n. ·\n이해관계자 별 적용 방식\n기술적정책적 지원 체계 활용\n·\n본 가이드라인은 정부 및 산학연 기관이 함께 협력하는 인공지능 안전신뢰성 지원 체계를 구축하는데 아래와 같이 \n·\n·\n·\n활용이 가능하다. 기업 및 공공기관 종사자들이 인공지능 안전성과 신뢰성을 이해하고책임 있는 인공지능 개발 및 운영 방안을 익힐 수 \n, \n있도록 교육을 제공. 인공지능 알고리즘의 편향성 및 안전성을 평가할 수 있는 공공 테스트 환경 제공. 인공지능 신뢰성 거버넌스 협력 네트워크를 운영하여 국내외 주요 인공지능 관계자가 지속적으로 규정을 보완하고 최신 \n기술 트렌드를 반영. 이해관계자\n적용 방식\n인공지능 사업자\n책임 있는 인공지능 구축 및 내부 거버넌스 체계 강화.",
    "metadata": {
      "page": 10,
      "source": "4._260122_고영향_인공지능_사업자_책무_가이드라인-1.pdf",
      "chunk_index": 0,
      "chunk_method": "semantic_local"
    }
  },
  {
    "text": "인공지능 개발사업자는 고영향 \n에 관한 사업자 책무를 준수하기 위한 조직을 \nAI\n지정운영해야 함\n·\n. 특히 일정 규모 이상의 사업자는 독립성객관성을 갖춘 내부 조직의 평가 또는 외부 \n·\n독립기관의 검인증을 통해 객관성을 확보해야 함\n·\n. 규제기관 및 정책 결정자\n인공지능 정책 수립 강화. 인공지능 기업들이 가이드라인을 자율적으로 준수할 수 있도록혁신적인 인공지능 \n, \n기술이 법적 부담 없이 실험될 수 있는 환경을 제공해야 함. 인공지능 법제도 개선을 위해 산업계\n학계\n시민사회와 협력하는 공공민간 \n·\n, \n, \n-\n인공지능 협의체 등을 통해 의견을 수렴하며지속적으로 규정을 업데이트해야 함\n, \n. 인공지능 이용자\n인공지능의 신뢰성에 대한 이해 및 권리 보호 강화. 이용자들은 인공지능이 제공하는 정보에 대해 기술적으로 가능한 범위에서 \n설명가능성을 요구할 권리를 가지며인공지능의 결정이 불합리하다고 판단될 경우 \n, \n이의를 제기할 수 있는 절차를 보장받아야 함. 공공기관은 인공지능을 활용할 때이용자들이 인공지능의 결정 방식과 데이터 활용 \n, \n방식에 대해 알 수 있도록 투명성 보고서 및 인공지능 사용 공시 시스템을 운영하기 \n위해 노력해야 함. 참조문서\n설명\n韓\n\n인공지능 시스템의 추적가능성 및 변경이력 확보\n04: \n美\n\n내 모든 \n에 \n항목으로써 별도로 기술\nPlaybook \nfunction\n‘Transparency and Documentation’ \nEU\n제\n조규제 준수 입증을 위해 기술 문서 작성 및 최신화 수행\n11\n: \n제\n조안전한 인공지능 활용을 위해 성능 제한위험 등 주요 정보를 이해하기 쉽게 제공\n12\n: \n, \n제\n조안전한 시스템 사용을 위해 목적성능위험 등 핵심 정보를 명확히 제공\n18\n: \n, \n, \n부속서 \n인공지능 시스템의 목적구조개발 과정데이터 등 핵심 요소를 기술 문서로 정리\nIV: \n, \n, \n, \n",
    "metadata": {
      "page": 10,
      "source": "4._260122_고영향_인공지능_사업자_책무_가이드라인-1.pdf",
      "chunk_index": 1,
      "chunk_method": "semantic_local"
    }
  }
]