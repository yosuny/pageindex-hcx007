[
  {
    "text": "인공지능 안정성 확보 가이드라인\n56\n인공지능 안정성 확보 가이드라인\n<자가점검 체크리스트> \n□ 안전사고를 전담하거나 총괄하는 대응 조직 또는 기능이 공식적으로 지정되어 있는가? □ 안전사고 대응에 대한 최종 책임자 및 의사결정 권한이 명확히 설정되어 있는가? □ 보안䞻법률䞻윤리䞻정책 등 다양한 관점이 대응 조직 또는 협업 구조에 반영되어 있는가? □ 대응 조직이 내부 이해관계로부터 독립적으로 안전 판단을 내릴 수 있는 구조인가? □ 사고 징후를 신속히 인지하고 대응 조직으로 보고할 수 있는 내부 전달 체계가 마련되어 있는가?",
    "metadata": {
      "page": 56,
      "source": "2._260122_인공지능_안전성_확보_가이드라인.pdf",
      "chunk_index": 0,
      "chunk_method": "semantic_local"
    }
  },
  {
    "text": "□ 외부 전문가 또는 전문기관과 협력할 수 있는 절차가 사전에 준비되어 있는가? 참고\n 국제 AI 안전 보고서 2025(International AI Safety Report 2025)\n 3.1 위험 관리 개요(3.1 Risk management overview)\n위험 관리\n실천/방법\n설명\n활용 분야\n문서화\n(Documentaion)\n• 학습 데이터, 모델 설계와 기능, 의도된 \n사용 사례, 한계 및 위험 등을 추적하기 \n위한 인공지능시스템 문서화 모범사례, \n지침 및 요구사항이 다수 존재\n• ‘모델 카드(Model Cards)’와 ‘시스템 \n카드(System Cards)’는 대표적인 인공지능 \n문서화 기준 사례임\n위험 등록부\n(Risk Register)\n• 모든 위험을 기록하고 우선순위, 책임자, \n대응 계획을 저장하는 위험 관리 도구로, \n규제 준수를 위해 활용되기도 함\n• 사이버보안을 비롯한 다양한 산업에서 일반적으로 \n사용되며 최근에는 인공지능 분야에도 적용됨\n내부고발자 보호\n(Whistleblower \nProtection)\n• 많은 인공지능 기술 발전이 독점적으로 \n이루어지므로, 내부고발자는 인공지능 \n사업자 내 위험성을 당국에 알리는 중요한 \n역할을 수행할 수 있음\n• 내부고발자에 대한 인센티브 및 보호는 고도화된 \n인공지능 위험 거버넌스의 핵심 요소가 될 것으로 \n예상됨\n사고 보고\n(Incident \nReporting)\n• 인공지능 개발 또는 배포 과정에서 발생한 \n직접적 䞻 간접적 피해 사례를 체계적으로 \n기록 䞻 공유하는 절차\n• 인사, 사이버보안 등 다양한 분야에서 일반화되어 \n있으며, 인공지능 분야에서도 점차 확대되고 있음\n위험 관리 체계 (Risk \nManagement \nFrameworks)\n• 조직 전체의 위험 관리 공백을 줄이고 \n다양한 위험 관리 활동(상기 모든 절차 \n포함)을 통합 䞻 구조화하며, 위험 관련 \n역할과 책임을 명확히 하고 이해 상충을 \n방지하기 위한 견제와 균형 장치를 \n포함하는 체계\n• 다른 안전 중시 산업에서는 ‘3선 방어(Three \nLines of Defence)’ 체계(위험 소유, 감독, \n감사의 분리)가 널리 사용되며, 고도화된 \n인공지능을 개발하는 사업자에도 유용하게 적용 \n가능함\n",
    "metadata": {
      "page": 56,
      "source": "2._260122_인공지능_안전성_확보_가이드라인.pdf",
      "chunk_index": 1,
      "chunk_method": "semantic_local"
    }
  }
]