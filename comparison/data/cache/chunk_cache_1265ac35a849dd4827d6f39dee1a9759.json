[
  {
    "text": "31\n2-1\n인공지능이 도출한 최종결과 및 기준에 대한 근거 마련\n투명성 및 설명가능성 확보\n2-1-1. 개발사업자\n목표\n인공지능의 투명성 및 설명가능성을 확보하고가능한 범위에서 설명가능성을 높이기 위한 다양한 기술적 \n, \n조치를 마련해야 함. 설명\n개발사업자는 인공지능의 주요 작동원리기능 및 한계를 문서화하여 투명성 확보에 기여해야 함\n, \n. 학습 구조알고리즘 구조인공지능 모델 등을 포함할 수 있음\n- \n, \n, \n. 시스템 아키텍처 또는 알고리즘이 조정된 경우 문서화된 자료를 수정할 수 있음\n- \n. 개발사업자는 기술적인력적으로 가능한 범위에서 이용자가 이해하기 쉽도록 내용을 기재해야 하고\n·\n, \n시각화 도구 또는 요약보고서 등 보조 수단을 활용할 수 있음. 참고\n\n신뢰할 수 있는 인공지능 개발안내서\n韓 \n요구사항 \n인공지능 모델 명세 및 추론 결과에 대한 설명 제공\n- \n11. 세부요구사항 \n인공지능 모델의 명세를 투명하게 제공하는가\n- \n11-1. ? \nNIST AI RMF\n美 \n-\n인공지능 수명주기 전반의 문서화 정책 수립\nGOVERN 1.4: \n-\n인공지능 시스템의 목적기술 사양성능 기준을 명확히 정의하고 문서화\nMAP 2.1: \n, \n, \n-\n책임 있는 인공지능 시스템 사용을 위해 인공지능 모델 설명을 문서화하고출력 해석 \nMEASURE 2.9: \n, \n기준 정의\nEU AI ACT\n- 제\n조제항\n13\n1\n: 고위험 인공지능 시스템 배포자는 이용자가 시스템 출력을 해석하고 활용할 수 있도록 설계 \n \n및 개발 \n사업자 구분\n자가점검\n인공지능의 주요 작동원리기능 및 한계를 문서화하여 인공지능의 투명성을 확보하는데\n, \n기여하고 있는가? 설명 가능성을 확보하기 위한 기술적 조치나 대안 조치를 적용하고 있는가?",
    "metadata": {
      "page": 32,
      "source": "4._260122_고영향_인공지능_사업자_책무_가이드라인-1.pdf",
      "chunk_index": 0,
      "chunk_method": "semantic_local"
    }
  },
  {
    "text": "개발     \n \n개발 \n",
    "metadata": {
      "page": 32,
      "source": "4._260122_고영향_인공지능_사업자_책무_가이드라인-1.pdf",
      "chunk_index": 1,
      "chunk_method": "semantic_local"
    }
  }
]