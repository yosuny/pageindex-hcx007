[
  {
    "text": "- 19 -\nEU, “Systemic Risk Impact Assessment”에서의 시스템적 리스크 식별 체계\n- 유럽연합(EU)는 인공지능법 제55조1항에 근거하여, 범용 인공\n지능(GPAI) 모델의 ‘시스템적 위험 영향평가(Systemic Risk \nImpact Assessment)’ 프레임워크를 담은 행동강령 발표\n* 시스템적 위험 : 범용 인공지능 모델이 고영향 역량으로 인해 발생하는 \n위험으로, 그 영향 범위가 넓어 시장 전반에 중대한 영향을 미치거나 \n공중 보건, 안전, 공공 보안, 기본권, 사회 전반에 부정적 영향을 줄 수 \n있으며, 이로 인해 가치사슬 전체에 걸쳐 대규모로 확산될 수 있는 위험\n \n- 이 프레임워크는 시스템적 위험 분석과 수용 여부 결정을 \n지원하기 위해, 체계적인 절차에 따라 시스템적 위험을 식별\n하고, 식별된 각 위험에 대해 시스템적 위험 시나리오를 개발\n하는 과정을 포함\n출처 : EU(2025). “Code of Practice for General-Purpose AI Models - Safety and Security Chapter”\n· ‘인공지능기술 일반 차원’은 인공지능기술 자체의 작동 방식에 기인한 위험을 다루며, 앞에서 다룬 작동원리의 \n체계에 따르면 데이터 수집, 분석·판단, 피드백의 단계가 이 차원에 속함\n      - 주로 정보의 수집 또는 처리를 다루는 기본권(개인정보자기결정권, 사생활의 비밀)이 평가 기준으로 고려되며, \n이 기본권은 인공지능기술을 이용하는 한, 반드시 검토 필요\n      - 인공지능기술 일반 차원에서 검토가 필요한 기본권은 아래 표를 참조할 수 있음\n5) 헌재 2005.7.21. 선고 2003헌마282(교육정보시스템), 판례집 17-2, 81, 90.",
    "metadata": {
      "page": 20,
      "source": "5._260122_인공지능_영향평가_가이드라인.pdf",
      "chunk_index": 0,
      "chunk_method": "semantic_local"
    }
  },
  {
    "text": "6) 헌재 2003.10.30. 선고 2002헌마518(좌석안전띠 착용의무), 판례집 15-2하, 185, 206. 7) 헌재 1994.2.24. 선고 92헌바43, 판례집 6-1, 72, 75; 헌재 1996.8.29. 선고 93헌바57, 판례집 8-2, 46, 56. 잠재적 영향 기본권\n기본권 내용 및 침해 시나리오\n개인정보자기결정권\n개인정보의 공개와 이용에 관하여 스스로 결정할 권리5)\n- 개인적 대화 내용 학습 후, 다른 사용자에 대한 답변에 예시로 노출\n- AI 예측·추론시스템의 불투명한 작동 방식으로 통제권 형해화\n- 이미 모델이 학습한 개인정보에 대한 사후 통제 불가능\n사생활의 비밀\n의사에 반하여 사생활 영역이 공개되지 않을 권리6)\n- 음성 AI 비서의 사적 대화 무단 수집·공유\n- 헬스케어 AI의 건강 정보를 동의 범위를 넘어 무단 공유\n- 사용자의 비공개 행동 패턴(예: 성적 지향, 경제 활동, 일상) 분석 및 공개\n평등권\n본질적으로 동일한 것의 합리적 이유 없는 차별 금지7)\n- 편견에 기반한 특정 데이터의 가중치 조정으로 차별적 분류\n- 차별을 유발하는 요소와 상관관계가 높은 부차적 변수들을 통한 우회적 차별\n재산권\n사적 유용성 및 처분권을 지닌 재산적 가치 있는 구체적인 권리의 보호\n- 생성형 AI가 개인의 창작물을 무단 학습·활용하여 원작자의 경제적 기회 박탈\n- 콘텐츠 접근 통제를 위한 기술적 장치를 회피하거나 무력화하여 비즈니스 모델 훼손\n인공지능기술 일반 차원에서 고려되는 기본권\n",
    "metadata": {
      "page": 20,
      "source": "5._260122_인공지능_영향평가_가이드라인.pdf",
      "chunk_index": 1,
      "chunk_method": "semantic_local"
    }
  }
]