[
  {
    "text": "- 37 -\n지능에 의해 직접적으로 생명이나 기본권에 영향을 받는 자뿐만 아니라, 이들과의 관계나 \n환경 변화로 인해 근접하게 영향을 받는 간접 피영향자와 의도치 않은 또는 예상치 못한 \n피영향자까지 모두 고려하는 것이 권고됩니다. 특히 의도하지 않은 영향을 사전에 완벽히 \n파악하기는 어렵더라도, 다양한 가능성을 열어두고 진행하는 브레인스토밍은 잠재적 위험에 \n대한 선제적 대비 체계를 구축한다는 점에서 중요한 의미가 있습니다. Q.",
    "metadata": {
      "page": 38,
      "source": "5._260122_인공지능_영향평가_가이드라인.pdf",
      "chunk_index": 0,
      "chunk_method": "semantic_local"
    }
  },
  {
    "text": "기술적 작동원리를 분석할 때 무엇을 중점적으로 검토하여야 하나요? A. 작동원리를 분석할 때는 데이터 수집, 분석 및 판단, 결정, 피드백 등 인공지능 활용 \n모든 단계에서 인공지능 기술이 작동하는 방식에 집중하여 조사해야 합니다. 이를 통해 \n향후 단계별로 적절한 보호 조치와 완화 방안을 설계할 수 있는 기초 자료를 확보할 \n수 있습니다. Q. 위험 시나리오는 어떤 기준으로 작성하는 것이 효과적인가요? A. 동일한 기술이라도 활용 분야에 따라 위험의 종류가 다르므로, 실제 제품 또는 서비스가 \n목표로 하는 분야와 상황을 기준으로 구체적인 시나리오를 작성해야 합니다. 예를 들어, \n동일하게 데이터를 분석하여 패턴을 찾아내고, 미래를 예측하는 기술이라도 ‘중환자실 \n위험 징후 감지’를 위해 활용되는 경우, 진단 오류로 인한 환자의 생명권 침해가 주된 \n위험이지만, ‘환자 답변용 챗봇’의 경우, 데이터 보안 실패에 따른 민감 정보의 유출이 \n주요 위험이 됩니다. 이 과정에서는 발생 가능성이 낮더라도 최대한 다양한 위험을 폭넓게 \n제시하는 것이 필요하며, 필요한 경우 외부 전문가의 조력을 받아 심층적인 시나리오를 \n확보하는 것이 권장됩니다. Q. 인공지능이 침해할 수 있는 기본권은 어떻게 식별하나요? A. 평가의 편의를 위해 ‘인공지능 기술 일반 차원’과 ‘제품·서비스 차원’으로 구분하여 식별하는 \n것이 좋습니다. 인공지능 기술의 일반적인 작동 방식에서 기인하는 개인정보자기결정권\n이나 사생활의 비밀 같은 기본권은 물론이고, 서비스의 활용 맥락에 따라 생명권, 평등권, \n표현의 자유, 직업의 자유 등이 침해될 가능성이 있는지 포괄적으로 식별해야 합니다. Q.",
    "metadata": {
      "page": 38,
      "source": "5._260122_인공지능_영향평가_가이드라인.pdf",
      "chunk_index": 1,
      "chunk_method": "semantic_local"
    }
  },
  {
    "text": "식별된 위험이 기본권에 영향을 미치는지 어떻게 판단하나요? A. 식별된 위험 시나리오를 바탕으로 기본권에 미치는 영향의 현실성을 종합적으로 판단해야 \n합니다. 위험 시나리오가 실제 기본권의 보호 영역을 제약하는지 판단하고, 그 영향의 \n규모와 기간, 발생 가능성을 자체적으로 평가합니다. 이 과정에서 해당 제품 또는 서비스와 \n",
    "metadata": {
      "page": 38,
      "source": "5._260122_인공지능_영향평가_가이드라인.pdf",
      "chunk_index": 2,
      "chunk_method": "semantic_local"
    }
  }
]