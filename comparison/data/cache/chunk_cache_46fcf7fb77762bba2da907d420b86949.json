[
  {
    "text": "23\n위험관리정책 개선\n1-1-5.",
    "metadata": {
      "page": 24,
      "source": "4._260122_고영향_인공지능_사업자_책무_가이드라인-1.pdf",
      "chunk_index": 0,
      "chunk_method": "semantic_local"
    }
  },
  {
    "text": "개발사업자\n이용사업자\n목표\n인공지능 수명주기 동안 위험관리정책을 조직 내외부 변화에 대응시키고 지속적으로 개선해야 함. 설명\n개발 및 이용사업자는 위험 처리 방안이 적용된 이후에 파급효과를 재평가함으로써 위험 요소가 실제로 \n제거방지완화되었는지 확인하고이에 대한 피드백을 위험관리체계 개선에 사용해야 함\n, \n, \n, \n. 이는 \n의 모니터링 및 대응과 밀접하며대응 결과를 위험관리정책의 개선에 이용할 수 있음\n- \n3-2-1\n, \n. 참고\n\n신뢰할 수 있는 인공지능 개발안내서\n韓 \n요구사항 \n인공지능 시스템의 위험 관리 계획 및 수행\n- \n01. 세부요구사항 \n위험 요소를 제거 및 방지하거나 영향을 완화하기 위한 방안을 마련하였는가\n- \n01-2 \n? \nNIST AI RMF\n美 \n인공지능 시스템의 목적 달성 여부 판단을 위해 개발 또는 배포 진행 여부를 결정\n- MANAGE 1.1: \n- MANAGE 4: 인공지능 위험 대응 및 개선을 위해 모니터링사고 대응 등 지속적 개선 활동 수립이행문서화\n, \n·\n·\n인공지능 시스템의 지속적인 개선을 위한 프로세스 정립 및 운영\n- MANAGE 4.2 \nEU AI ACT\n제조제항고위험 인공지능의 수명주기 동안 반복적 위험 관리 절차 및 정기 검토 절차 정의\n- \n9\n2\n: \n제조제항고위험 인공지능이 의도된 목적대로 작동하는지 확인하기 위한 정기 테스트 설계\n- \n9\n6\n: \n사업자 구분\n자가점검\n위험 처리 방안 적용 후해당 방안의 파급효과를 재평가하고 있는가\n, \n? 위험 처리 방안에 대한 피드백을 위험관리정책 개선에 사용하고 있는가? 개발 이용 \n개발 이용 \n사례\n카카오 그룹의 책임있는 \n를 위한 가이드라인\nAI\n카카오 그룹은 인공지능 기술 발전과 이에 따른 새로운 위험 요소에 대응하기 위해\n윤리원칙을 계층화하여 정비하고\n \n, AI \n, \n가이드라인과 체크리스트를 고도화하였음. 좌개정 전우개정 후\n(\n: \n, \n: \n)\n",
    "metadata": {
      "page": 24,
      "source": "4._260122_고영향_인공지능_사업자_책무_가이드라인-1.pdf",
      "chunk_index": 1,
      "chunk_method": "semantic_local"
    }
  }
]