[
  {
    "text": "16\n장\n3\n고영향 인공지능사업자\n책무 조치사항\n위험관리방안의 수립운영\n3.1 \n·\n관련 기술고시 조문\n제조위험관리방안의 수립ㆍ운영\n4\n(\n)\n인공지능개발사업자 및 인공지능이용사업자이하 사업자라 한다는 고영향 인\n \n(\n“\n”\n)\n① \n공지능의 위험관리를 위하여 다음 각 호의 사항이 포함된 위험관리방안을 수립ㆍ운영하여야 한다. 위험관리정책 수립 및 이행\n  1. 위험관리 조직체계 수립 및 운영\n  2. 사업자는 제항의 위험관리방안을 인공지능 수명주기의 모든 과정에서 준수하여야 한다\n1\n. ② \n사업자는 최신의 위험관리방안을 주기적으로 점검ㆍ갱신하고 그 변경내역을 관리하여야 한다. ③ \n타 법령의 유사 조치사항\n법령\n조항\n내용\n지능정보화 기본법\n제\n조안전성 \n60\n(\n보호조치)\n지능정보화 기본법 제\n조는 지능정보기술 및 지능정보서비스의 안\n60\n전성 확보를 위한 최소한의 보호조치를 명시하고 있다이는 고영향 \n. 인공지능이 야기할 수 있는 광범위한 위험을 관리하고 안전성을 확\n보해야 한다는 인공지능 사업자 책무의 기본 전제와 동일하다\n단\n. , \n지능정보화 기본법은 안전성 보호조치를 권고할 수 있다고 명시하\n여 강제성이 상대적으로 낮다. 소프트웨어 진흥법\n제\n조소프트웨어안\n30\n(\n전 확보)\n인공지능 역시 소프트웨어를 통해 구현되므로\n소프트웨어의 기본적\n, \n인 안전 원칙이 인공지능의 안전성 확보에도 적용될 수 있다\n단\n. , \n소프트웨어 진흥법은 일반적인 소프트웨어의 안정성 및 보안 취약\n점 등 기술적 결함으로 인한 위험에 중점을 두지만\n인공지능 기본\n, \n법은 알고리즘의 비결정성\n인과관계의 불분명성\n자율적 학습 및 \n, \n, \n진화 등으로 인해 예측 불가능한 결과를 고려한다이러한 인공지능 \n. 고유의 비기술적\n사회적\n윤리적 위험에 대한 고려는 소프트웨어 \n, \n, \n진흥법에서는 찾아보기 어렵다.",
    "metadata": {
      "page": 17,
      "source": "4._260122_고영향_인공지능_사업자_책무_가이드라인-1.pdf",
      "chunk_index": 0,
      "chunk_method": "semantic_local"
    }
  },
  {
    "text": "",
    "metadata": {
      "page": 17,
      "source": "4._260122_고영향_인공지능_사업자_책무_가이드라인-1.pdf",
      "chunk_index": 1,
      "chunk_method": "semantic_local"
    }
  }
]