[
  {
    "text": "인공지능 안정성 확보 가이드라인\n34\n인공지능 안정성 확보 가이드라인\n1-3. 위험 식별 결과의 문서화 및 관리\n[목표] 위험 평가䞻위험 완화䞻사고 대응 및 보고 단계까지 연속적으로 활용될 수 있도록 위험 식별 결과를 \n체계적으로 문서화하고 관리\n[목표 달성을 위해 고려해야 할 사항] 이 목표를 달성하기 위하여 인공지능사업자는 다음 사항을 종합적으로 \n고려\n(1) 위험 식별 결과의 표준화된 문서화\n• 사업자는 자사의 인공지능시스템이 초래할 수 있는 위험을 사전에 식별할 책임이 있으며, 그 식별 \n과정은 객관성과 검증가능성을 갖추어야 함. 이는 단순한 직관적 판단이나 일회성 점검이 아니라, \n구조화된 방법론에 기반해 제3자도 이해 䞻 평가 가능한 방식으로 문서화되어야 함을 의미\n• 고시에 따라, 사업자는 위험 식별과 관련하여 최소한 다음 각 항목을 포함하여 문서화:\n- 위험의 식별번호 및 명칭\n- 위험식별 시점\n- 위험식별 방법\n- 위험식별 결과\n• 위 항목들은 위험 식별의 존재 여부와 절차적 정당성을 확인하기 위한 최소 요건으로서, 추가적으로 \n다음과 같은 항목을 포함:\n- 위험의 유형 및 관련 수명주기 단계\n- 현존 위험 또는 잠재적 위험 여부\n- 식별 근거(사례, 분석 결과, 테스트 방법 등)\n(2) 고유 식별번호 부여 및 이력 관리\n• 각 위험에는 고유한 식별번호를 부여하여야 하며, 이를 통해 동일 위험이 반복적으로 식별䞻검토되는 \n경우에도 일관되게 관리\n레드팀 테스트는 실제 공격자의 관점에서 창의적이고 악의적인 공격을 시도해 취약점을 발견하는 방법으로, \n주요 인공지능 사업자들이 모델 출시 전 필수적으로 수행한다. 시스템 수준 모니터링은 인공지능시스템이 실제 운영되는 과정에서 발생하는 위험을 실시간으로 탐지하는 방법\n이다. 주요 인공지능 사업자들은 배포된 모델의 사용 패턴을 지속적으로 모니터링해 예상치 못한 위험이나 오용 \n사례를 조기에 발견하고 대응한다.",
    "metadata": {
      "page": 34,
      "source": "2._260122_인공지능_안전성_확보_가이드라인.pdf",
      "chunk_index": 0,
      "chunk_method": "semantic_local"
    }
  },
  {
    "text": "",
    "metadata": {
      "page": 34,
      "source": "2._260122_인공지능_안전성_확보_가이드라인.pdf",
      "chunk_index": 1,
      "chunk_method": "semantic_local"
    }
  }
]