[
  {
    "text": "20\n위험 식별\n1-1-2. 개발사업자\n이용사업자\n목표\n사람의 생명신체의 안전 및 기본권에 중대한 영향을 미칠 수 있는 위험을 식별해야 함\n, \n. 설명\n개발사업자는 인공지능의 설계데이터 수집모델 학습테스트 등 개발 전 과정에서 발생 가능한 사람의 \n, \n, \n, \n생명신체의 안전 및 기본권에 대한 잠재적 위험을 식별하기 위해 노력해야 함\n, \n. 이용사업자는 개발사업자로부터 제공받은 정보를 바탕으로실제 환경에서 인공지능이 이용될 때 발생할 \n, \n수 있는 사람의 생명신체의 안전 및 기본권에 대한 위험을 식별하고관련 데이터사고 신고불만 사항\n, \n, \n(\n, \n, \n수리 내역 등를 통해 지속적으로 갱신하기 위해 노력해야 함\n)\n. 참고\n\n신뢰할 수 있는 인공지능 개발안내서\n韓 \n요구사항 \n인공지능 시스템에 대한 위험관리 계획 및 수행\n- \n01.",
    "metadata": {
      "page": 21,
      "source": "4._260122_고영향_인공지능_사업자_책무_가이드라인-1.pdf",
      "chunk_index": 0,
      "chunk_method": "semantic_local"
    }
  },
  {
    "text": "세부요구사항 \n인공지능 시스템 수명주기에 걸쳐 나타날 수 있는 위험 요소를 분석하였는가\n- \n01-1. ? \nNIST AI RMF\n美 \n-\n인공지능 시스템 배포에 따른 위험관리를 위해 정기적인 위험 식별 및 추적 체계 구축\nMEASURE 3.1: \nEU AI ACT\n- 제조제항제호인공지능 수명주기 동안 위험 식별분석 및 정기적인 검토갱신 \n9\n2\na\n: \n\n\n사업자 구분\n자가점검\n인공지능 개발 과정에서 발생 가능한 위험을 식별하고 있는가? 인공지능 운영 과정에서 발생 가능한 위험을 식별하고 운영 데이터를 통해 관련 내용을 \n지속적으로 갱신하기 위해 노력하고 있는가? 개발  \n이용 \n \n \n사례\n위험요소 예시\n에서는 생성형 인공지능에 대해 아래와 같은 위험 요소를 명시함\nOECD\n. 인공지능 환각또는 설득력 있지만 부정확한 출력\n\"\n\" \n허위 및 오해의 소지가 있는 콘텐츠\n지적재산권 침해\n직업 및 노동 시장 변화 예자동화에 따른 일자리 대체 및 노동시장 내 불균형 심화 가능성\n(\n: \n)\n에너지 소비와 환경 예생성형 \n모델 학습 및 추론 시 높은 에너지 소비로 인한 환경 부담 증가\n(\n: \nAI \n)\n편견고정관념 증폭 및 개인 정보 보호 문제\n, \n잠재적인 미래 위험 및 우려 사항\n",
    "metadata": {
      "page": 21,
      "source": "4._260122_고영향_인공지능_사업자_책무_가이드라인-1.pdf",
      "chunk_index": 1,
      "chunk_method": "semantic_local"
    }
  }
]