[
  {
    "text": "인공지능 안정성 확보 가이드라인\n28\n인공지능 안정성 확보 가이드라인\n• 최근 발생한 사례(예: 최근 2년 이내), 복수의 연구에서 반복적으로 확인된 위험(예: 3개 이상 연구), \n직접적 또는 1차적 간접 인과관계를 가진 위험을 우선 고려. 다만 이는 인공지능의 특성과 적용 분야에 \n따라 조정䞻보완\n(4) 위험 식별 시 고려 요소\n• 인공지능의 수명주기 및 특수성:\n- 인공지능은 기획䞻개발䞻배포䞻운영䞻종료에 이르는 각 단계에서 서로 다른 성격의 위험을 내포 \n하므로, 특정 단계에 국한하지 않고 전 과정에서 잠재적 위험을 점검\n- 범용성 여부, 재학습䞻미세조정의 빈도, 적용 산업 분야, 자율성 및 외부 시스템과의 연동 수준 등에 \n따라 위험의 유형과 영향 범위는 달라질 수 있음. 이에 따라 사업자는 자사 인공지능의 고유한 \n특성을 면밀히 분석하여, 일반적으로 알려진 위험 목록 외에도 해당 인공지능에 특화된 위험을 \n추가로 식별\n| 인공지능의 특수성에 따른 식별 위험 예시 |\n인공지능 특수성\n식별 위험 예시\n범용 AI\n• 다양한 전용 가능성으로 예측하기 어려운 위험\n특화 AI\n• 해당 분야 특유의 고영향 요소 집중 관리\n의료 AI\n• 오진으로 인한 생명 위험\n금융 AI\n• 잘못된 투자 조언으로 인한 재산 손실\n자율주행\n• 물리적 안전사고 \n자율성/연동성 높은 시스템\n• 외부 API 연계로 영향 범위 확대\n- 또한 위험은 그 사용 맥락과 대상 사용자, 기술적 구성에 따라 다르게 발현.",
    "metadata": {
      "page": 28,
      "source": "2._260122_인공지능_안전성_확보_가이드라인.pdf",
      "chunk_index": 0,
      "chunk_method": "semantic_local"
    }
  },
  {
    "text": "따라서 다음의 특성들을 \n종합적으로 고려\n| 인공지능의 특수성에 따른 고려사항 |\n인공지능 특수성\n식별 위험 예시\n시스템 기능 및 범용성\n• 범용 생성모델일수록 예측 불가능성과 전이 위험이 높기 때문에, 범용성 및 \n오용 가능성을 기반으로 위험 범위 확장 \n모델 능력 및 임계치 수준\n• 고도화된 자율성, 자기개선, 조작 능력 등은 위험성 증가 요인이므로, 역량 \n임계치 기반 위험 시나리오 수립\n사용자 특성 및 사용 방식\n• 비전문가 사용자, 자동화 환경, 불충분한 사용자 교육은 위험을 증가시킬 수 \n있으므로, 사용자 오류 가능성과 인간-시스템 상호작용 오류를 포함해 위험 식별\n상호작용 및 연계성\n• 외부 시스템, API, 툴과의 연결은 새로운 위험 벡터를 제공하기 때문에, 도구 \n사용 능력 및 방식의 맥락 분석 필요\n운영 환경 및 사회적 영향\n• 특정 정치 䞻 문화 䞻 법적 환경에서의 위험성이 상이할 수 있으므로, 사회적 맥락 \n기반 위험 요소를 별도로 식별\n",
    "metadata": {
      "page": 28,
      "source": "2._260122_인공지능_안전성_확보_가이드라인.pdf",
      "chunk_index": 1,
      "chunk_method": "semantic_local"
    }
  }
]