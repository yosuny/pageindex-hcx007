[
  {
    "text": "인공지능 안정성 확보 가이드라인\n40\n인공지능 안정성 확보 가이드라인\n• 외부 참여는 모든 위험 평가에 필수적인 것은 아니나, 위험의 사회적 파급력이 크거나 기술적 판단을 \n넘어선 가치 판단이 요구되는 경우에 유용\n(5) 외부 자문 절차의 운영\n• 사업자는 위험 평가 결과에 대한 해석이 기술 영역을 넘어 사회적 판단을 필요로 하는 경우, 외부 \n전문가의 의견을 수렴하기 위해 노력\n• 이를 위해 외부 자문위원회 또는 위험 해석 자문단을 운영할 수 있으며, 자문은 서면 의견서, 간담회, \n평가 보고서 검토 등의 방식 활용\n• 외부 자문 결과는 최종 평가 결과에 어떻게 반영되었는지, 또는 반영하지 않은 경우 그 사유를 함께 \n문서화하여 관리\n(6) 운영의 투명성과 기록 관리\n• 위험평가조직의 구성, 역할, 운영 방식, 외부 참여 여부 등은 내부 규정이나 운영 문서로 명확히 정리\n• 또한 평가 과정에서 사용된 기준, 판단 근거, 의사결정 이력은 이후 검증이나 재평가 시 참고할 수 \n있도록 기록䞻관리\n<자가점검 체크리스트> \n□ 위험 평가를 전담하는 조직 또는 이에 준하는 체계를 구성䞻운영하고 있는가? □ 위험평가조직이 기술䞻윤리䞻정책䞻보안 등 다양한 관점을 반영할 수 있는 전문성을 갖추고 있는가? □ 위험평가조직이 개발䞻사업 부서로부터 조직적䞻의사결정상 독립성을 유지하도록 설계되어 있는가? □ 평가자와 평가 대상 간의 이해 충돌을 방지하기 위한 기준이나 절차를 마련하고 있는가? □ 위험의 성격에 따라 외부 기관 또는 전문가의 참여䞻자문을 활용할 수 있는 절차를 갖추고 있는가? □ 위험평가조직의 운영 방식과 평가 과정이 투명하게 기록䞻관리되고 있는가?",
    "metadata": {
      "page": 40,
      "source": "2._260122_인공지능_안전성_확보_가이드라인.pdf",
      "chunk_index": 0,
      "chunk_method": "semantic_local"
    }
  },
  {
    "text": "2-3. 위험 평가 기준䞻방법䞻절차 설정\n[목표] 식별된 위험을 객관적이고 일관되게 평가하기 위하여 위험 평가 기준, 평가 방법 및 평가 절차를 \n사전에 마련하고, 이를 체계적으로 적용\n[목표 달성을 위해 고려해야 할 사항] 이 목표를 달성하기 위하여 사업자는 다음 사항을 종합적으로 고려\n(1) 평가 체계 설정의 기본 원칙\n• 현 시점에서 인공지능 위험을 평가하는 통일되거나 지배적인 단일 방법은 존재하지 않음\n",
    "metadata": {
      "page": 40,
      "source": "2._260122_인공지능_안전성_확보_가이드라인.pdf",
      "chunk_index": 1,
      "chunk_method": "semantic_local"
    }
  }
]