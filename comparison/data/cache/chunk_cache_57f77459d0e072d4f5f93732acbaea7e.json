[
  {
    "text": " \n03 수명주기 전반에 걸친 위험관리\n39\n[목표 달성을 위해 고려해야 할 사항] 이 목표를 달성하기 위하여 사업자는 다음 사항을 종합적으로 고려\n(1) 위험 평가 조직의 설치 및 역할\n• 인공지능사업자는 식별된 위험을 평가하기 위하여 위험 평가를 전담하는 조직(이하 “위험평가 조직”) \n을 구성\n• 위험평가조직은 위험 평가의 기획䞻수행, 평가 결과의 정리 및 내부 보고, 필요 시 외부 검토 연계를 \n담당하는 핵심적 관리 주체로 기능\n(2) 구성 원칙 및 전문성 확보\n• 인공지능 위험은 기술적 복잡성과 사회적䞻윤리적 민감성을 동시에 지니므로, 위험평가조직은 다학제적 \n관점이 반영된 구성 필요\n• 예를 들어 다음과 같은 전문성이 조직 내에 포함:\n- 모델 아키텍처, 학습 데이터, 성능 평가를 이해할 수 있는 기술 전문가\n- 인권, 개인정보 보호, 사회적 영향 등을 검토할 수 있는 정책䞻윤리 전문가\n- 보안 취약점과 악용 가능성을 평가할 수 있는 사이버보안 전문가\n• 이를 통해 위험 평가가 특정 부서나 단일 관점에 편중되지 않도록 하는 것이 중요\n(3) 조직의 독립성 및 객관성 확보\n• 위험평가조직은 기술 개발 부서, 사업 운영 부서, 마케팅 부서 등과 조직적으로 분리된 위치에서 운영 \n필요\n• 특히 평가 결과가 사업 일정이나 성과 압박에 의해 왜곡되지 않도록, 평가 결과를 최고책임자 또는 \n독립된 의사결정 라인에 직접 보고할 수 있는 체계를 마련하는 것이 중요\n• 아울러 평가자와 평가 대상 간의 이해 충돌을 방지하기 위해, 평가자가 자신이 직접 관여한 개발 \n프로젝트를 평가하지 않도록 하는 내부 기준을 마련하거나 평가 기준과 절차를 표준화하여 개인적 \n판단의 영향을 최소화하는 방식도 고려\n(4) 외부 기관 또는 전문가의 참여\n• 사업자는 필요한 경우 외부 기관 또는 전문가를 위험평가조직에 참여시킬 수 있으며, 다음과 같은 \n주체를 포함\n- 독립적인 감사기관 또는 연구기관\n- 학계 전문가\n- 법률䞻인권䞻윤리 분야 전문가\n- 소비자 보호 또는 시민사회 분야 전문가\n",
    "metadata": {
      "page": 39,
      "source": "2._260122_인공지능_안전성_확보_가이드라인.pdf",
      "chunk_index": 0,
      "chunk_method": "semantic_local"
    }
  }
]